"""
Secure Database Profiler

YOU run queries on YOUR database with YOUR credentials.
Claude NEVER sees actual data, only metadata (counts, types, ranges).

Security:
- Database credentials stay on YOUR server
- Only metadata sent to Claude
- No PII/sensitive data exposure
- No actual row data sent

Based on #1 BIRD benchmark approach (67-72% accuracy).
"""

import logging
import psycopg2
from psycopg2.extras import RealDictCursor
from typing import Dict, List, Any, Optional
import json
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


class SecureDatabaseProfiler:
    """
    Gathers database statistics WITHOUT exposing data to LLM.

    Security principles:
    1. Only YOU have database credentials
    2. Only metadata (counts, types) sent to LLM
    3. No actual data values sent to LLM (except safe samples)
    4. No connection info sent to LLM
    """

    # Columns to NEVER sample (PII/sensitive)
    SENSITIVE_PATTERNS = [
        'email', 'mail', 'phone', 'mobile', 'tel',
        'name', 'first_name', 'last_name', 'full_name',
        'ssn', 'social_security', 'passport', 'license',
        'address', 'street', 'city', 'zip', 'postal',
        'ip_address', 'credit_card', 'account_number',
        'password', 'pwd', 'secret', 'token', 'api_key',
        'dob', 'birth', 'age', 'salary', 'income'
    ]

    def __init__(self, db_config: Dict[str, str]):
        """
        Initialize with YOUR database credentials.
        These NEVER leave your server.

        Args:
            db_config: {
                'host': 'localhost',
                'port': 5432,
                'database': 'analytics',
                'user': 'user',
                'password': 'password'
            }
        """
        self.db_config = db_config
        self.conn = None
        logger.info("üîí Secure profiler initialized (credentials never sent to LLM)")

    def connect(self):
        """Connect to database (YOUR credentials, YOUR server)"""
        try:
            self.conn = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            logger.info(f"‚úÖ Connected to database: {self.db_config['database']}")
        except Exception as e:
            logger.error(f"‚ùå Failed to connect to database: {e}")
            raise

    def disconnect(self):
        """Close connection"""
        if self.conn:
            self.conn.close()
            logger.info("üîå Database connection closed")

    def profile_database(self,
                        include_sample_values: bool = True,
                        max_sample_values: int = 5,
                        exclude_tables: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Gather ONLY metadata (no sensitive data).

        What we send to Claude:
        - ‚úÖ Table names
        - ‚úÖ Column names and types
        - ‚úÖ Row counts
        - ‚úÖ NULL counts, distinct counts
        - ‚úÖ Min/max for dates/numbers (if not sensitive)
        - ‚ö†Ô∏è  Sample values (ONLY for safe columns like status codes)

        What we DON'T send:
        - ‚ùå Actual row data
        - ‚ùå Database credentials
        - ‚ùå PII (emails, names, SSNs, etc.)

        Args:
            include_sample_values: Include sample values for safe columns only
            max_sample_values: Max samples per column
            exclude_tables: Tables to skip (e.g., audit logs)

        Returns:
            Metadata dictionary safe to send to Claude
        """
        exclude_tables = exclude_tables or []

        metadata = {
            "generated_at": datetime.now().isoformat(),
            "database_type": "postgresql",
            "database_name": self.db_config['database'],
            "tables": {}
        }

        # Get all tables
        tables = self._get_tables(exclude_tables)
        logger.info(f"üìä Profiling {len(tables)} tables...")

        for table_name in tables:
            logger.info(f"  üìã Profiling: {table_name}")

            try:
                table_metadata = {
                    "row_count": self._get_row_count(table_name),
                    "columns": self._get_column_metadata(
                        table_name,
                        include_sample_values,
                        max_sample_values
                    )
                }
                metadata["tables"][table_name] = table_metadata

            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è  Failed to profile {table_name}: {e}")
                continue

        logger.info(f"‚úÖ Profiled {len(metadata['tables'])} tables successfully")
        return metadata

    def _get_tables(self, exclude_tables: List[str]) -> List[str]:
        """Get list of all tables (excluding system tables)"""
        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT table_name
            FROM information_schema.tables
            WHERE table_schema = 'public'
              AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)

        all_tables = [row[0] for row in cursor.fetchall()]
        tables = [t for t in all_tables if t not in exclude_tables]

        cursor.close()
        logger.info(f"Found {len(tables)} tables (excluded {len(exclude_tables)})")
        return tables

    def _get_row_count(self, table_name: str) -> int:
        """Get total row count (safe to share)"""
        cursor = self.conn.cursor()

        # Use COUNT(*) for exact count
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]

        cursor.close()
        return count

    def _get_column_metadata(self,
                            table_name: str,
                            include_samples: bool,
                            max_samples: int) -> Dict[str, Any]:
        """
        Get metadata for all columns in a table.
        """
        cursor = self.conn.cursor(cursor_factory=RealDictCursor)

        # Get column info from information_schema
        cursor.execute("""
            SELECT
                column_name,
                data_type,
                is_nullable,
                column_default,
                character_maximum_length
            FROM information_schema.columns
            WHERE table_name = %s
            ORDER BY ordinal_position
        """, (table_name,))

        columns_info = cursor.fetchall()
        columns_metadata = {}

        for col_info in columns_info:
            col_name = col_info['column_name']

            # Build metadata for this column
            col_metadata = {
                "data_type": col_info['data_type'],
                "nullable": col_info['is_nullable'] == 'YES',
                "max_length": col_info['character_maximum_length'],
                "has_default": col_info['column_default'] is not None
            }

            # Get statistics (counts only, no actual data)
            stats = self._get_column_stats(table_name, col_name, col_info['data_type'])
            col_metadata.update(stats)

            # Optionally include sanitized sample values
            if include_samples and self._is_safe_for_samples(col_name):
                samples = self._get_safe_samples(table_name, col_name, max_samples)
                if samples:
                    col_metadata['sample_values'] = samples

            columns_metadata[col_name] = col_metadata

        cursor.close()
        return columns_metadata

    def _get_column_stats(self, table_name: str, col_name: str, data_type: str) -> Dict:
        """
        Get statistics about a column (counts, not data).
        """
        cursor = self.conn.cursor()
        stats = {}

        try:
            # Count NULLs (always safe)
            cursor.execute(f"""
                SELECT COUNT(*)
                FROM {table_name}
                WHERE {col_name} IS NULL
            """)
            stats['null_count'] = cursor.fetchone()[0]

            # Count distinct values (always safe)
            cursor.execute(f"""
                SELECT COUNT(DISTINCT {col_name})
                FROM {table_name}
            """)
            stats['distinct_count'] = cursor.fetchone()[0]

            # For numeric/date columns, get ranges (usually safe)
            if data_type in ['integer', 'bigint', 'numeric', 'real', 'double precision',
                            'date', 'timestamp', 'timestamp with time zone',
                            'timestamp without time zone']:
                try:
                    cursor.execute(f"""
                        SELECT MIN({col_name}), MAX({col_name})
                        FROM {table_name}
                        WHERE {col_name} IS NOT NULL
                    """)
                    result = cursor.fetchone()
                    if result:
                        min_val, max_val = result
                        stats['min_value'] = str(min_val) if min_val else None
                        stats['max_value'] = str(max_val) if max_val else None
                except:
                    # Skip if aggregation fails
                    pass

        except Exception as e:
            logger.debug(f"Failed to get stats for {table_name}.{col_name}: {e}")

        cursor.close()
        return stats

    def _is_safe_for_samples(self, col_name: str) -> bool:
        """
        Check if column is safe to include sample values.

        NEVER sample PII or sensitive data.
        """
        col_lower = col_name.lower()
        return not any(pattern in col_lower for pattern in self.SENSITIVE_PATTERNS)

    def _get_safe_samples(self, table_name: str, col_name: str, limit: int) -> List[str]:
        """
        Get sample values for SAFE columns only (like status codes, categories).

        Only samples if:
        1. Column name is safe (no PII keywords)
        2. Low cardinality (< 50 distinct values)
        """
        cursor = self.conn.cursor()

        try:
            # Only get samples if distinct count is low (probably categories/codes)
            cursor.execute(f"""
                SELECT COUNT(DISTINCT {col_name})
                FROM {table_name}
            """)
            distinct_count = cursor.fetchone()[0]

            # Only sample if it's a low-cardinality column
            if distinct_count > 50:
                cursor.close()
                return []

            # Get most common values
            cursor.execute(f"""
                SELECT {col_name}, COUNT(*) as freq
                FROM {table_name}
                WHERE {col_name} IS NOT NULL
                GROUP BY {col_name}
                ORDER BY freq DESC
                LIMIT %s
            """, (limit,))

            samples = [str(row[0]) for row in cursor.fetchall()]
            cursor.close()
            return samples

        except Exception as e:
            logger.debug(f"Failed to get samples for {table_name}.{col_name}: {e}")
            cursor.close()
            return []

    def save_metadata(self, metadata: Dict, output_dir: str = "metadata") -> str:
        """
        Save metadata to file (this is what we'll send to Claude).

        Returns:
            Path to saved file
        """
        # Create output directory
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        # Save with timestamp
        filename = f"db_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = output_path / filename

        with open(filepath, 'w') as f:
            json.dump(metadata, f, indent=2)

        file_size_kb = filepath.stat().st_size / 1024

        logger.info("="*70)
        logger.info("‚úÖ METADATA SAVED")
        logger.info("="*70)
        logger.info(f"File: {filepath}")
        logger.info(f"Size: {file_size_kb:.1f} KB")
        logger.info(f"Tables: {len(metadata['tables'])}")
        logger.info(f"Total Columns: {sum(len(t['columns']) for t in metadata['tables'].values())}")
        logger.info("="*70)

        return str(filepath)

    def print_security_summary(self, metadata: Dict):
        """Print summary of what will/won't be sent to Claude"""
        total_tables = len(metadata['tables'])
        total_columns = sum(len(t['columns']) for t in metadata['tables'].values())
        total_rows = sum(t['row_count'] for t in metadata['tables'].values())

        # Count columns with samples
        columns_with_samples = 0
        for table in metadata['tables'].values():
            for col in table['columns'].values():
                if 'sample_values' in col:
                    columns_with_samples += 1

        print("\n" + "="*70)
        print("üîí SECURITY SUMMARY: What Claude Will See")
        print("="*70)

        print(f"\nüìä Statistics:")
        print(f"  ‚Ä¢ Tables: {total_tables}")
        print(f"  ‚Ä¢ Columns: {total_columns}")
        print(f"  ‚Ä¢ Total Rows: {total_rows:,}")
        print(f"  ‚Ä¢ Columns with safe samples: {columns_with_samples}/{total_columns}")

        print(f"\n‚úÖ Claude WILL see:")
        print("  ‚Ä¢ Table and column names")
        print("  ‚Ä¢ Data types")
        print("  ‚Ä¢ Row counts")
        print("  ‚Ä¢ NULL/distinct counts")
        print("  ‚Ä¢ Min/max values (dates/numbers)")
        print(f"  ‚Ä¢ Sample values for {columns_with_samples} safe columns (status codes, etc.)")

        print(f"\nüîí Claude WILL NOT see:")
        print("  ‚Ä¢ Database credentials")
        print("  ‚Ä¢ Actual customer/user data")
        print("  ‚Ä¢ PII (emails, names, addresses, SSNs, etc.)")
        print("  ‚Ä¢ Connection strings")
        print("  ‚Ä¢ Query results")

        print("="*70 + "\n")


def main():
    """
    Example usage: Run this on YOUR server with YOUR credentials.
    """
    import os
    from dotenv import load_dotenv

    load_dotenv()

    # YOUR database config (stays on YOUR server)
    db_config = {
        'host': os.getenv('DB_HOST', 'localhost'),
        'port': int(os.getenv('DB_PORT', 5432)),
        'database': os.getenv('DB_DATABASE', 'analytics'),
        'user': os.getenv('DB_USER', 'wren_user'),
        'password': os.getenv('DB_PASSWORD', 'wren_password')
    }

    profiler = SecureDatabaseProfiler(db_config)

    print("üîê Connecting to database...")
    profiler.connect()

    print("\nüìä Gathering metadata (no sensitive data)...")
    metadata = profiler.profile_database(
        include_sample_values=True,  # Only for safe columns
        max_sample_values=5,
        exclude_tables=['audit_log', 'sessions']  # Skip these tables
    )

    # Show security summary
    profiler.print_security_summary(metadata)

    # Save to file
    filepath = profiler.save_metadata(metadata)

    profiler.disconnect()

    print(f"\n‚úÖ Done! Metadata saved to: {filepath}")
    print(f"\nüì§ Next step: Run 'python src/llm_descriptor.py' to generate descriptions")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    main()
