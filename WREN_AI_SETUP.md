# Wren AI Setup with Claude (Anthropic)

## What Was Fixed

### The Problem
The application was returning **404 errors** for all natural language queries because:
- Docker Compose was using `ghcr.io/canner/wren-engine-ibis:latest` (a query execution engine)
- This image does **NOT** provide the `/v1/asks` endpoint needed for text-to-SQL conversion
- The actual **Wren AI Service** with AI capabilities was missing

### The Solution
Replaced the incorrect Docker image with the proper Wren AI stack:
- âœ… **wren-ai-service** (v0.29.0) - AI-powered text-to-SQL using Claude
- âœ… **Qdrant** - Vector database for semantic search
- âœ… **Claude (Anthropic)** - LLM for natural language understanding
- âœ… **OpenAI embeddings** - For semantic similarity (very cheap, ~$0.0001/query)

---

## Architecture

```
User Question
    â†“
Streamlit App (port 8501)
    â†“
Wren AI Service (port 5555)
    â”œâ”€â†’ Claude API (text-to-SQL via LiteLLM)
    â”œâ”€â†’ OpenAI API (embeddings for semantic search)
    â”œâ”€â†’ Qdrant (vector database)
    â””â”€â†’ Wren Engine (SQL execution)
         â†“
    PostgreSQL Database
         â†“
    Results back to user
```

---

## Prerequisites

You need **two API keys**:

1. **Anthropic API Key** (required)
   - Get it from: https://console.anthropic.com/
   - Used for: Natural language to SQL conversion
   - Model: `claude-sonnet-4-20250514`

2. **OpenAI API Key** (required for embeddings)
   - Get it from: https://platform.openai.com/
   - Used for: Text embeddings only (semantic search)
   - Model: `text-embedding-3-small`
   - Cost: ~$0.0001 per query (very cheap)

> **Note:** If you don't want to use OpenAI for embeddings, you can configure a local embedding model in `wren-ai-config.yaml`. See "Advanced Configuration" below.

---

## Setup Instructions

### 1. Configure Environment Variables

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your API keys
nano .env  # or use your preferred editor
```

Add your keys:
```bash
ANTHROPIC_API_KEY=sk-ant-your-actual-key-here
OPENAI_API_KEY=sk-your-openai-key-here
```

### 2. Start the Services

```bash
# Stop existing services (if running)
docker-compose down

# Pull latest images
docker-compose pull

# Start all services
docker-compose up -d

# Watch the logs to see when ready
docker-compose logs -f wren-ai
```

Wait for this message:
```
wren-ai-service | INFO: Application startup complete
wren-ai-service | INFO: Uvicorn running on http://0.0.0.0:5555
```

This usually takes **1-2 minutes** on first start.

### 3. Verify Services are Running

```bash
# Check service health
docker-compose ps

# All services should show "healthy" or "Up"
# - postgres: healthy
# - wren-engine: Up
# - qdrant: Up
# - wren-ai: healthy
# - streamlit-app: Up
```

### 4. Test the Application

1. Open: http://localhost:8501
2. You should see your database schema loaded
3. Try asking a question:
   - "Show top 10 customers by orders"
   - "What was total revenue last month?"
   - "What's our average order value?"

If everything is configured correctly, you should get SQL generated by Claude and results from your database!

---

## Troubleshooting

### Issue: Wren AI service fails to start

**Check logs:**
```bash
docker-compose logs wren-ai
```

**Common causes:**
1. Missing API keys in `.env`
2. Invalid API keys
3. Qdrant not ready (it starts first)

**Solution:**
```bash
# Restart just the AI service
docker-compose restart wren-ai

# Or recreate everything
docker-compose down -v
docker-compose up -d
```

### Issue: Still getting 404 errors

**Verify the endpoint:**
```bash
# Test health endpoint
curl http://localhost:5555/health

# Should return: {"status":"ok"} or similar
```

**Check logs:**
```bash
docker-compose logs streamlit-app | grep WREN_URL
# Should show: WREN_URL=http://wren-ai:5555
```

### Issue: "Query timeout" or slow responses

**Adjust timeouts in config:**
Edit `wren-ai-config.yaml`:
```yaml
llm:
  timeout: 180  # Increase from 120

engine:
  config:
    timeout: 90  # Increase from 60
```

Then restart:
```bash
docker-compose restart wren-ai
```

### Issue: OpenAI API costs concerns

The OpenAI API is **only used for embeddings**, which are extremely cheap:
- ~$0.00002 per 1,000 tokens
- Average query: ~50 tokens = $0.000001 (one millionth of a dollar)
- 10,000 queries = ~$0.01 (one cent)

If you still want to avoid OpenAI, see "Advanced Configuration" below.

---

## Advanced Configuration

### Using a Local Embedding Model

Edit `wren-ai-config.yaml` to replace OpenAI embeddings:

```yaml
# Replace OpenAI embeddings with Sentence Transformers
embedder:
  provider: sentence_transformers_embedder
  models:
    - model: all-MiniLM-L6-v2  # Local model
      kwargs:
        device: cpu  # or "cuda" if you have GPU
```

Then remove `OPENAI_API_KEY` from `.env` and restart.

### Using a Different Claude Model

Edit `wren-ai-config.yaml`:

```yaml
llm:
  provider: litellm_llm
  models:
    - model: claude-opus-4-20250514  # More powerful
      kwargs:
        temperature: 0
        max_tokens: 4096
```

Available models:
- `claude-sonnet-4-20250514` (recommended - balanced)
- `claude-opus-4-20250514` (most powerful)
- `claude-3-5-sonnet-20240620` (legacy)

### Changing Qdrant Settings

To persist Qdrant data across restarts, the volume is already configured:
```yaml
volumes:
  qdrant_data:/qdrant/storage
```

To reset the vector database:
```bash
docker-compose down
docker volume rm wren_ai_qdrant_data
docker-compose up -d
```

---

## Files Changed

| File | Change |
|------|--------|
| `docker-compose.yml` | Added Qdrant, replaced wren-ai image, updated ports |
| `wren-ai-config.yaml` | **NEW** - Wren AI configuration for Claude |
| `.env.example` | Added OpenAI API key, updated documentation |

---

## Cost Estimation

**Anthropic (Claude) - Main Cost:**
- Text-to-SQL queries: ~1,000-3,000 tokens each
- Cost: ~$0.003 per query (using Sonnet 4)
- 100 queries/day = ~$0.30/day = $9/month

**OpenAI (Embeddings) - Minimal Cost:**
- Embeddings: ~50 tokens per query
- Cost: ~$0.000001 per query
- 100 queries/day = ~$0.0001/day = $0.003/month (negligible)

**Total: ~$9-10/month** for moderate use (100 queries/day)

---

## Next Steps

1. âœ… Set up your API keys in `.env`
2. âœ… Start the services with `docker-compose up -d`
3. âœ… Test natural language queries
4. âœ… Monitor logs for any issues
5. ðŸ“Š Start asking questions about your data!

---

## Support

If you encounter issues:

1. Check logs: `docker-compose logs <service-name>`
2. Verify health: `docker-compose ps`
3. Test endpoints directly: `curl http://localhost:5555/health`
4. Review this guide's troubleshooting section

For Wren AI specific issues:
- GitHub: https://github.com/Canner/WrenAI
- Docs: https://docs.getwren.ai/

---

**Last Updated:** 2025-11-15
